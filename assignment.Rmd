# Human Activity Recognition
========================================================

The goal of this project is to predict the manner in which they did the exercise.

# -
library(caret)
When you look at the basic pml.testing data you can observe a lot of NA value in many variable. There you can handle the out of sample error. The variables are unnessesary so we can use dim reduction and drop out these columns. If we drop out them , drop out needed at the training set too. Whit this step we can also improve our model too.

Load the data and caret for predictions
```{r ,cache=TRUE}
library(caret)
library(randomForest)
pml.training <- read.csv("data/pml-training.csv")
pml.testing <- read.csv("data/pml-testing.csv")

```

```{r}
myvars.test <- c("user_name","raw_timestamp_part_1","raw_timestamp_part_2","cvtd_timestamp","new_window","num_window","roll_belt","pitch_belt","yaw_belt","total_accel_belt","gyros_belt_x","gyros_belt_y","gyros_belt_z","accel_belt_x","accel_belt_y","accel_belt_z","magnet_belt_x","magnet_belt_y","magnet_belt_z","roll_arm","pitch_arm","yaw_arm","total_accel_arm","gyros_arm_x","gyros_arm_y","gyros_arm_z","accel_arm_x","accel_arm_y","accel_arm_z","magnet_arm_x","magnet_arm_y","magnet_arm_z","roll_dumbbell","pitch_dumbbell","yaw_dumbbell","gyros_dumbbell_x","gyros_dumbbell_y","gyros_dumbbell_z","accel_dumbbell_x","accel_dumbbell_y","accel_dumbbell_z","magnet_dumbbell_x","magnet_dumbbell_y","magnet_dumbbell_z","roll_forearm","pitch_forearm","yaw_forearm","total_accel_forearm","gyros_forearm_x","gyros_forearm_y","gyros_forearm_z","accel_forearm_x","accel_forearm_y","accel_forearm_z","magnet_forearm_x","magnet_forearm_y","magnet_forearm_z","problem_id")

myvars.train <- c("user_name","raw_timestamp_part_1","raw_timestamp_part_2","cvtd_timestamp","new_window","num_window","roll_belt","pitch_belt","yaw_belt","total_accel_belt","gyros_belt_x","gyros_belt_y","gyros_belt_z","accel_belt_x","accel_belt_y","accel_belt_z","magnet_belt_x","magnet_belt_y","magnet_belt_z","roll_arm","pitch_arm","yaw_arm","total_accel_arm","gyros_arm_x","gyros_arm_y","gyros_arm_z","accel_arm_x","accel_arm_y","accel_arm_z","magnet_arm_x","magnet_arm_y","magnet_arm_z","roll_dumbbell","pitch_dumbbell","yaw_dumbbell","gyros_dumbbell_x","gyros_dumbbell_y","gyros_dumbbell_z","accel_dumbbell_x","accel_dumbbell_y","accel_dumbbell_z","magnet_dumbbell_x","magnet_dumbbell_y","magnet_dumbbell_z","roll_forearm","pitch_forearm","yaw_forearm","total_accel_forearm","gyros_forearm_x","gyros_forearm_y","gyros_forearm_z","accel_forearm_x","accel_forearm_y","accel_forearm_z","magnet_forearm_x","magnet_forearm_y","magnet_forearm_z","classe")

```

Slicing the cols
```{r ,cache=TRUE}
train <- pml.training[myvars.train]
test <- pml.testing[myvars.test]
```


## Model

There are a lot of variable and observation. So we need to control the randomforest algorithm. 
I used 6 fold cross validated random forest. It's running time was acceptable and I got 1 Accuracy and 0.999 Kappa so the model was really good. After this accuracy no boosting or bagging required.

```{r cache=TRUE}
fit <- train(classe~., method="rf", data=train,  trControl = trainControl(method = "cv", number = 6))
```

```{r}
fit
```

Predicting and the answers to each problem_id
```{r}
pred <- predict(fit, test)
answers = cbind(test$problem_id,as.character(pred))
answers
```

## Appendix

